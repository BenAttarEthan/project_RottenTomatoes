# -*- coding: utf-8 -*-
"""scrapper_RT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y75Oom797jZY5zdMpeIeVyQ0iVWqLjQ3
"""

#!pip install selenium
#!pip install webdriver-manager
#!apt install chromium-chromedriver
#!cp /usr/lib/chromium-browser/chromedriver /usr/bin
import requests
import time
import selenium
from bs4 import BeautifulSoup
from selenium.webdriver import ActionChains
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.select import Select
from webdriver_manager.chrome import ChromeDriverManager
import sys

sys.path.insert(0,'/usr/lib/chromedriver')

#driver = webdriver.Chrome(ChromeDriverManager().install())


def web_scraper():
    """
    This function scrap the "AT HOME" movies from ROTTEN TOMATOES
    """

    nb = 6
    url_base = 'https://www.rottentomatoes.com/'
    page_nb = str(nb)
    print('********************')
    # Test if the page exists
    try:
      url = url_base + 'browse/movies_at_home' #/?page=' + page_nb
      #open(url)
      # **************************
      chrome_options = webdriver.ChromeOptions()
      chrome_options.add_argument('--headless')
      chrome_options.add_argument('--no-sandbox')
      chrome_options.add_argument('--disable-dev-shm-usage')
      wd = webdriver.Chrome('chromedriver',options=chrome_options)
      wd.get("https://www.rottentomatoes.com/browse/movies_at_home")
      for i in range(10):
        try :
          python_button = wd.find_element(By.XPATH, '//*[@id="main-page-content"]/div/div[5]/button')
          print(wd.current_url)
          python_button.click()
          time.sleep(1)
          nb += 1
          url = wd.current_url
          print(url)
          response = requests.get(url)
          print(response)
          print('OK')
        except:
          print("NOK")
      # **************************
      #response = requests.get(url)
      movies_url = []
      #test the request and find all the movies on the page
      if response.ok:
          #python_button.click()
          soup = BeautifulSoup(response.text)
          main_movies = soup.find_all('tile-dynamic', {'isvideo': 'true'})
          #Let's go to the movie page to catch contents
          for movie_url in main_movies:
            #python_button.click()
            #time.sleep(5)
            movie_page = requests.get('https://www.rottentomatoes.com' +
            movie_url.find('button').get('data-video-player-overlay-media-url'))
            if movie_page.ok:
              movie_soup = BeautifulSoup(movie_page.text)
              movie_info = {'Title': movie_soup.find('score-board').find('h1').string,
                                'Tomatometer': movie_soup.find('score-board').get('tomatometerscore')}
              movie_infos = movie_soup.find('ul', {'class': 'content-meta info'}).find_all('li')
              for content in movie_infos:
                try:
                  #python_button.click()
                  #time.sleep(2)
                  movie_info[content.find('div').string] = content.find('div', {'class': 'meta-value'}).string.strip()
                except AttributeError:
                  if content.find('div', {'class': 'meta-value'}).find_all('a'):
                    movie_info[content.find('div').string] = [c.string.strip() for c in
                                                                        content.find('div', {'class': 'meta-value'}) \
                                                                            .find_all('a')]
            print(movie_info)
    except ValueError:
        print('cc')


def main():
    web_scraper()


# /html/body/div[4]/main/div[1]/div/div[3]/div/div/a[1]/tile-dynamic/div/span[2]
# /html/body/div[4]/main/div[1]/div/div[3]/div/div/a[3]/tile-dynamic/div/span[1]
if __name__ == '__main__':
    main()